{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,cifar10\n",
    "from tensorflow.keras import Model,layers,backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Art Dataset\n",
    "#Before loading the art dataset,upload the kagal key which is the json file\n",
    "\n",
    "# copy kaggle account file \n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# downloading data from kaggle\n",
    "!kaggle datasets download -d thedownhill/art-images-drawings-painting-sculpture-engraving\n",
    "# !kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri\n",
    "\n",
    "# unzip data\n",
    "!unzip /content/art-images-drawings-painting-sculpture-engraving.zip\n",
    "!unzip /content/brain-tumor-classification-mri.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect_kaggle_dataset(sTraindir,sTestDir,imgHt,imgWt,aDirs):\n",
    "  # preprocessing the dataset loaded from kaggle\n",
    "  # create train and test lists \n",
    "  train_images = list()\n",
    "  test_images = list()\n",
    "\n",
    "  # add only directories, whose images are required to be added\n",
    "  dirs = aDirs\n",
    "\n",
    "  # upload images from directories as grey images, resize it to 128 (could be any other 8 multiple size)\n",
    "  # then add it in train or test list, after adding images covert list to array for training mode\n",
    "  #\n",
    "  artHt= imgHt\n",
    "  artWt = imgWt\n",
    "  for directory in glob(sTraindir):\n",
    "      if directory.split(\"/\")[-1] in dirs:\n",
    "          for img in glob(f\"{directory}/*\"):\n",
    "              img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "              if img is not None:\n",
    "                  img = cv2.resize(img, (int(artHt), int(artWt)))\n",
    "                  train_images.append(img)\n",
    "\n",
    "  for directory in glob(sTestDir):\n",
    "      if directory.split(\"/\")[-1] in dirs:\n",
    "          for img in glob(f\"{directory}/*\"):\n",
    "              img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "              if img is not None:\n",
    "                  img = cv2.resize(img, (int(artHt), int(artWt)))\n",
    "                  test_images.append(img)\n",
    "\n",
    "  train_images = np.array(train_images)\n",
    "  test_images = np.array(test_images)\n",
    "  return train_images,test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Art dataset params\n",
    "sArtTrainDir = \"/content/dataset/dataset_updated/training_set/*\"\n",
    "sArtTestDir = \"/content/dataset/dataset_updated/validation_set/*\"\n",
    "artImgHt = 256\n",
    "artImgWt = 256\n",
    "artDirs = [\"drawings\",\"sculpture\"]\n",
    "x_artTrain,x_artTest = _collect_kaggle_dataset(sArtTrainDir,sArtTestDir,artImgHt,artImgWt,artDirs)\n",
    "\n",
    "#brain tumor mri datset params\n",
    "sBtTrainDir = \"/content/Training/*\"\n",
    "sBtTestDir = \"/content/Testing/*\"\n",
    "btImgHt = 256\n",
    "btImgWt = 256\n",
    "dtDirs = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\n",
    "x_btTrain,x_btTest = _collect_kaggle_dataset(sBtTrainDir,sBtTestDir,btImgHt,btImgWt,dtDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATASET = \"MNIST\"  # MNIST or CIFAR10 or ART or BRAINTU\n",
    "_MISSING_RATE = 0.1\n",
    "_MISSING_TYPE = \"MCAR\" # MCAR OR MNAR\n",
    "\n",
    "def _process_data(x_data):\n",
    "    \"\"\"\n",
    "    Scales the dataset to the range [0, 1] and removes 40% of the pixels completely at random.\n",
    "    Args:\n",
    "        x_data: Dataset to be processed.\n",
    "    Returns: Processed dataset with and without missing pixels, and the missing mask.\n",
    "    \"\"\"\n",
    "    if len(x_data.shape) == 3:\n",
    "        x_data = np.expand_dims(x_data, axis=3)\n",
    "    x_data = x_data.astype('float32') / 255\n",
    "    missing_mask = ''\n",
    "\n",
    "    if _MISSING_TYPE == \"MCAR\":\n",
    "      number_channels = x_data.shape[3]\n",
    "      missing_mask = np.stack(\n",
    "          (np.random.choice([0, 1], size=(x_data.shape[0], x_data.shape[1], x_data.shape[2]),\n",
    "                            p=[1 - _MISSING_RATE, _MISSING_RATE]),) * number_channels, axis=-1)\n",
    "\n",
    "\n",
    "      x_data_md = x_data * (~missing_mask.astype(bool)).astype(int) + -1.0 * missing_mask\n",
    "      x_data_md[x_data_md == -1] = np.nan\n",
    "    elif _MISSING_TYPE == \"MNAR\":\n",
    "     x_data_md = x_data.copy()\n",
    "     if _DATASET == \"ART\" or _DATASET ==\"BRAINTU\":   \n",
    "       x_data_md[:,70:76,70:76] = np.nan\n",
    "     else:\n",
    "       x_data_md[:,10:12,10:12] = np.nan  \n",
    "     missing_mask = np.isnan(x_data_md)\n",
    "    else:\n",
    "      raise ValueError(\"Invalid missing type.\")\n",
    "\n",
    "    return x_data, x_data_md, missing_mask\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if _DATASET == \"MNIST\":\n",
    "        source = mnist\n",
    "        (x_train, _), (x_test, _) = source.load_data()\n",
    "    elif _DATASET == \"CIFAR10\":\n",
    "        source = cifar10\n",
    "        (x_train, _), (x_test, _) = source.load_data()\n",
    "    elif _DATASET == \"ART\":\n",
    "      x_train = x_artTrain\n",
    "      x_test = x_artTest\n",
    "    elif _DATASET == \"BRAINTU\":\n",
    "      x_train = x_btTrain\n",
    "      x_test = x_btTest\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset.\")\n",
    "\n",
    "    x_train, x_train_md, missing_mask_train = _process_data(x_train)\n",
    "    x_test, x_test_md, missing_mask_test = _process_data(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate MAE\n",
    "def _calculate_mae(missing_mask_test,x_test,x_test_imputed,algo):\n",
    "    missing_mask_test_flat = missing_mask_test.astype(bool).flatten()\n",
    "    mae = mean_absolute_error(x_test_imputed.flatten()[missing_mask_test_flat],\n",
    "                            x_test.flatten()[missing_mask_test_flat])\n",
    "\n",
    "    print(f\"[{algo}] MAE for the {_DATASET} dataset and missing type {_MISSING_TYPE}: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape \n",
    "img_width  = x_train.shape[1]\n",
    "img_height = x_train.shape[2]\n",
    "num_channels = 1 # Images are grey scale so 1 channel\n",
    "input_shape = (img_height, img_width, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Denoising Autoencoder model\n",
    "def _DAE(input_shape):\n",
    "\n",
    "    Input_img = K.Input(shape=input_shape)  \n",
    "    \n",
    "    #encoding architecture\n",
    "    x = K.Conv2D(64, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "    x = K.MaxPool2D( (2, 2), padding='same')(x)\n",
    "    x = K.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = K.MaxPool2D( (2, 2), padding='same')(x)\n",
    "    x = K.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded    = K.MaxPool2D( (2, 2), padding='same')(x)\n",
    "    \n",
    "    # decoding architecture\n",
    "    x = K.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = K.UpSampling2D((2, 2))(x)\n",
    "    x = K.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = K.UpSampling2D((2, 2))(x)\n",
    "    x = K.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = K.UpSampling2D((2, 2))(x)\n",
    "    decoded   = K.Conv2D(1, (3, 3),activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = K.Model(Input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Imputation\n",
    "def _linear_imputation(x_data):\n",
    "    x_test_md = x_data.copy()\n",
    "    iShape = x_test_md.shape\n",
    "    x_test_md = x_test_md.reshape(np.prod(iShape[:-1]), iShape[-1])\n",
    "    x_test_md = pd.DataFrame(x_test_md)\n",
    "    x_test_imp = (x_test_md.ffill()+x_test_md.bfill())/2\n",
    "    x_test_imp = x_test_imp.ffill().bfill()\n",
    "    x_test_imp = x_test_imp.values.reshape(iShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING Variational Autoencoder model\n",
    "\n",
    "# # ================= ############\n",
    "# # Encoder\n",
    "# define 4 conv2D, flatten and then dense\n",
    "# # ================= ############\n",
    "\n",
    "latent_dim = 32 # Number of latent dim parameters\n",
    "\n",
    "input_img = layers.Input(shape=input_shape, name='encoder_input')\n",
    "x = layers.Conv2D(64, (5,5), activation='relu')(input_img)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "\n",
    "conv_shape = K.int_shape(x) #Shape of conv to be provided to decoder\n",
    "#Flatten\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# Two outputs, for latent mean and log variance (std. dev.)\n",
    "#Use these to sample random variables in latent space to which inputs are mapped. \n",
    "z_mu = layers.Dense(latent_dim, name='latent_mu')(x)   #Mean values of encoded input\n",
    "z_sigma = layers.Dense(latent_dim, name='latent_sigma')(x)  #Std dev. (variance) of encoded input\n",
    "\n",
    "#REPARAMETERIZATION TRICK\n",
    "# Define sampling function to sample from the distribution\n",
    "# Reparameterize sample based on the process defined by Gunderson and Huang\n",
    "# into the shape of: mu + sigma squared x eps\n",
    "#This is to allow gradient descent to allow for gradient estimation accurately. \n",
    "def sample_z(args):\n",
    "  z_mu, z_sigma = args\n",
    "  eps = K.random_normal(shape=(K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n",
    "  return z_mu + K.exp(z_sigma / 2) * eps\n",
    "\n",
    "# sample vector from the latent distribution\n",
    "# z is the labda custom layer we are adding for gradient descent calculations\n",
    "  # using mu and variance (sigma)\n",
    "z = layers.Lambda(sample_z, output_shape=(latent_dim, ), name='z')([z_mu, z_sigma])\n",
    "\n",
    "#Z (lambda layer) will be the last layer in the encoder.\n",
    "# Define and summarize encoder model.\n",
    "encoder = Model(input_img, [z_mu, z_sigma, z], name='encoder')\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= ###########\n",
    "# Decoder\n",
    "#\n",
    "# ================= #################\n",
    "\n",
    "# decoder takes the latent vector as input\n",
    "decoder_input = layers.Input(shape=(latent_dim, ), name='decoder_input')\n",
    "\n",
    "# Need to start with a shape that can be remapped to original image shape as\n",
    "#we want our final utput to be same shape original input.\n",
    "#So, add dense layer with dimensions that can be reshaped to desired output shape\n",
    "x = layers.Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n",
    "# reshape to the shape of last conv. layer in the encoder, so we can \n",
    "x = layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "# upscale (conv2D transpose) back to original shape\n",
    "# use Conv2DTranspose to reverse the conv layers defined in the encoder\n",
    "x = layers.Conv2DTranspose(64, 3,padding='same', activation='relu',strides=2)(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation='relu',strides=1)(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "#x = layers.Conv2DTranspose(64, 3, activation='relu',strides=1)(x)\n",
    "#Can add more conv2DTranspose layers, if desired. \n",
    "#Using sigmoid activation\n",
    "x = layers.Conv2DTranspose(num_channels, 5, activation='sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Define and summarize decoder model\n",
    "decoder = Model(decoder_input, x, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# apply the decoder to the latent sample \n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vae_loss(x, z_decoded):\n",
    "    x = K.flatten(x)\n",
    "    z_decoded = K.flatten(z_decoded)\n",
    "    \n",
    "    # Reconstruction loss (as we used sigmoid activation we can use binarycrossentropy)\n",
    "    recon_loss = tf.keras.losses.binary_crossentropy(x, z_decoded) * img_width * img_height\n",
    "    # recon_loss = tf.keras.losses.binary_crossentropy(x, z_decoded) \n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -5e-1 * K.mean(1 + z_sigma - K.square(z_mu) - K.exp(z_sigma), axis=-1)\n",
    "    return K.mean(recon_loss + (0.5 * kl_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================\n",
    "# VAE \n",
    "# =================\n",
    "vae = Model(input_img, z_decoded, name='vae')\n",
    "vae.add_loss(_vae_loss(input_img, z_decoded))\n",
    "# Compile VAE\n",
    "vae.compile(optimizer='adam', loss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Linear Imputation\n",
    "x_test_LI_imp = _linear_imputation(x_test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NAN values with zero for traing and testing DAE and VAE\n",
    "x_train_pre = np.nan_to_num(x_train_md, nan=0.0)\n",
    "x_test_pre = np.nan_to_num(x_test_md, nan=0.0)\n",
    "x_test_mis_mask = np.isnan(x_test_md).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks for DAE and VAE\n",
    "callbacks =[]\n",
    "#will Reduce learning rate when a metric has stopped improving\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                               patience=10, min_lr=0))\n",
    "#Stop training when a monitored metric has stopped improving\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', mode='min', verbose=0,\n",
    "                                           patience=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing DAE\n",
    "DAE = _DAE(input_shape)\n",
    "dae_history = DAE.fit(x_train_pre,\n",
    "        x_train,\n",
    "        epochs = 50,\n",
    "        batch_size=128,\n",
    "        validation_split = 0.15,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks)\n",
    "x_test_DAE_imp = DAE.predict(x_test_pre)\n",
    "x_test_DAE_imp = x_test_pre * (~x_test_mis_mask.astype(bool)).astype(int) + x_test_DAE_imp * x_test_mis_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing VAE\n",
    "vae_history = vae.fit(x_train_pre, \n",
    "        x_train, \n",
    "        epochs = 50, \n",
    "        batch_size = 64, \n",
    "        validation_split = 0.15,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks)\n",
    "x_test_VAE_imp = vae.predict(x_test_pre)\n",
    "x_test_VAE_imp = x_test_pre * (~x_test_mis_mask.astype(bool)).astype(int) + x_test_VAE_imp * x_test_mis_mask    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot learning curve\n",
    "plt.legend(['train','val'])\n",
    "plt.plot(vae_history.history['loss'])\n",
    "plt.plot(vae_history.history['val_loss'])\n",
    "plt.plot(dae_history.history['loss'])\n",
    "plt.plot(dae_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Mean Absolute Error\n",
    "_calculate_mae(missing_mask_test,x_test,x_test_LI_imp,\"LI\")\n",
    "_calculate_mae(missing_mask_test,x_test,x_test_DAE_imp,\"DAE\")\n",
    "_calculate_mae(missing_mask_test,x_test,x_test_VAE_imp,\"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polt imputed images\n",
    "iImg = 28\n",
    "plt.figure(2,figsize=(2,2))\n",
    "plt.title('Original Image')\n",
    "plt.imshow(x_test[iImg][:,:,0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2,figsize=(4,4))\n",
    "plt.title('Missing Data Image')\n",
    "plt.imshow(x_test_md[iImg][:,:,0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2,figsize=(2,2))\n",
    "plt.title('Imputed Image')\n",
    "plt.imshow(x_test_VAE_imp[iImg][:,:,0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
